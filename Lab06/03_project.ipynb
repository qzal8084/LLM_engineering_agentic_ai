{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63826b6f",
   "metadata": {},
   "source": [
    "## A more advanced Document Q&A\n",
    "\n",
    "1. Setup ChromaDB with Persistent Storage\n",
    "2. Read Multiple PDFs from a directory and Add Metadata\n",
    "documents_info = [\n",
    "    {\"path\": \"attention_all_you_need.pdf\", \"category\": \"attention\"},\n",
    "    {\"path\": \"react.pdf\", \"category\": \"policy\"},\n",
    "    ...\n",
    "]\n",
    "3. Reduce the dimensionality of the vectors to 2D using t-SNE (t-distributed stochastic neighbor embedding)\n",
    "4. Visualizing the Vector Store\n",
    "5. Answer questions about any of the documents\n",
    "6. Use langchain library\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a63e295",
   "metadata": {},
   "source": [
    "We use langchain:\n",
    "```\n",
    "pip install langchain langchain-openai langchain-chroma langchain-text-splitters  langchain-community langchain-classic \n",
    "\n",
    "pip install plotly scikit-learn\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e598cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from langchain_classic.chains import RetrievalQA\n",
    "\n",
    "import PyPDF2\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "aval_api_key=os.getenv(\"AVALAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c23e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 2. CONFIGURATION\n",
    "# ===============================\n",
    "\n",
    "persist_directory = \"./chroma_db\"\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(\n",
    "    api_key=aval_api_key,\n",
    "    base_url=\"https://api.avalai.ir/v1\",\n",
    "    model=\"text-embedding-3-small\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27bd987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 3. LOAD MULTIPLE PDF DOCUMENTS\n",
    "# ===============================\n",
    "\n",
    "documents_info = [\n",
    "    {\"path\": \"documents/attention_all_you_need.pdf\", \"category\": \"attention\"},\n",
    "    {\"path\": \"documents/react.pdf\", \"category\": \"policy\"},\n",
    "    # Add more PDFs here...\n",
    "]\n",
    "\n",
    "all_documents = []\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "for info in documents_info:\n",
    "    filepath = info[\"path\"]\n",
    "    category = info[\"category\"]\n",
    "\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"File not found: {filepath}\")\n",
    "        continue\n",
    "\n",
    "    # Extract text from PDF\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        reader = PyPDF2.PdfReader(f)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            try:\n",
    "                text += page.extract_text() or \"\"\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    # Split into chunks\n",
    "    chunks = splitter.split_text(text)\n",
    "\n",
    "    # Add metadata + store as Document objects\n",
    "    for chunk in chunks:\n",
    "        all_documents.append(\n",
    "            Document(\n",
    "                page_content=chunk,\n",
    "                metadata={\"category\": category, \"source\": filepath}\n",
    "            )\n",
    "        )\n",
    "\n",
    "print(f\"Loaded {len(all_documents)} document chunks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0ef7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 4. BUILD CHROMADB VECTOR STORE\n",
    "# ===============================\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"pdf_docs\",\n",
    "    embedding_function=embedding_model,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "\n",
    "vectorstore.add_documents(all_documents)\n",
    "\n",
    "print(\"ChromaDB persisted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b5330d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one vector and find how many dimensions it has\n",
    "\n",
    "collection = vectorstore._collection\n",
    "sample_embedding = collection.get(limit=1, include=[\"embeddings\"])[\"embeddings\"][0]\n",
    "dimensions = len(sample_embedding)\n",
    "print(f\"The vectors have {dimensions:,} dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3644ac23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prework\n",
    "\n",
    "result = collection.get(include=['embeddings', 'documents', 'metadatas'])\n",
    "vectors = np.array(result['embeddings'])\n",
    "documents = result['documents']\n",
    "doc_types = [metadata['category'] for metadata in result['metadatas']]\n",
    "colors = [[ 'green', 'red'][['attention', 'policy'].index(t)] for t in doc_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6504b2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 5. TSNE VISUALIZATION\n",
    "# ===============================\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "reduced_vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "# Create the 2D scatter plot\n",
    "fig = go.Figure(data=[go.Scatter(\n",
    "    x=reduced_vectors[:, 0],\n",
    "    y=reduced_vectors[:, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(size=5, color=colors, opacity=0.8),\n",
    "    text=[f\"Type: {t}<br>Text: {d[:100]}...\" for t, d in zip(doc_types, documents)],\n",
    "    hoverinfo='text'\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='2D Chroma Vector Store Visualization',\n",
    "    scene=dict(xaxis_title='x',yaxis_title='y'),\n",
    "    width=800,\n",
    "    height=600,\n",
    "    margin=dict(r=20, b=10, l=10, t=40)\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3809102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 6. Q&A OVER ALL DOCUMENTS\n",
    "# ===============================\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_key=aval_api_key,\n",
    "    base_url=\"https://api.avalai.ir/v1\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=vectorstore.as_retriever()\n",
    ")\n",
    "\n",
    "query = \"What is the main idea behind the attention mechanism?\"\n",
    "answer = qa.invoke(query)\n",
    "\n",
    "print(\"\\nQUESTION:\", query)\n",
    "print(\"ANSWER:\", answer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
